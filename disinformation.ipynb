{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWgEkOAO9OVz"
   },
   "source": [
    "# Disinformation\n",
    "\n",
    "An example where an individual spreads a fake news among others and they discuss whether it is true or not, as well as some methods of preventing the spread of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jadeu-zIkL_s"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLAP7E4mYyqg"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/44.4 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/44.4 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/44.4 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.4/44.4 kB 313.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\algar\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.4.1-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\algar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\algar\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\algar\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\algar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\algar\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\algar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\algar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\algar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\algar\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\algar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
      "   ---------------------------------------- 0.0/255.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 255.2/255.2 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/436.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 436.6/436.6 kB 28.4 MB/s eta 0:00:00\n",
      "Downloading torch-2.4.1-cp312-cp312-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.7/199.4 MB 57.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 5.1/199.4 MB 53.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 7.6/199.4 MB 54.2 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 10.3/199.4 MB 54.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.2/199.4 MB 54.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 15.2/199.4 MB 54.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 17.8/199.4 MB 59.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 20.2/199.4 MB 54.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 22.5/199.4 MB 50.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 23.7/199.4 MB 50.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 25.0/199.4 MB 38.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 27.1/199.4 MB 38.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 28.7/199.4 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 31.4/199.4 MB 40.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 33.7/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 35.1/199.4 MB 46.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 36.2/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.3/199.4 MB 38.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 39.8/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 40.8/199.4 MB 32.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 42.6/199.4 MB 32.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 44.8/199.4 MB 32.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 47.0/199.4 MB 38.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 48.0/199.4 MB 38.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 49.3/199.4 MB 32.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 49.4/199.4 MB 28.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 50.2/199.4 MB 29.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 52.2/199.4 MB 31.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 54.7/199.4 MB 31.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 55.8/199.4 MB 29.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 57.0/199.4 MB 26.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 58.5/199.4 MB 27.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 59.8/199.4 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 61.5/199.4 MB 34.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 62.0/199.4 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 63.2/199.4 MB 27.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 65.3/199.4 MB 28.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 66.2/199.4 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 68.1/199.4 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 69.0/199.4 MB 27.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 70.7/199.4 MB 27.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 72.9/199.4 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 74.8/199.4 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 77.2/199.4 MB 38.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 79.2/199.4 MB 43.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 81.6/199.4 MB 46.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 82.7/199.4 MB 43.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 83.5/199.4 MB 38.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 85.9/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 87.6/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 88.1/199.4 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 89.8/199.4 MB 36.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 90.6/199.4 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 93.1/199.4 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 95.2/199.4 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 97.2/199.4 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 99.5/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 101.5/199.4 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 102.2/199.4 MB 40.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 104.1/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 106.1/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 106.6/199.4 MB 32.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 108.5/199.4 MB 32.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 110.9/199.4 MB 34.4 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 113.2/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 115.6/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 117.4/199.4 MB 43.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 119.6/199.4 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 120.4/199.4 MB 43.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 122.5/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 124.7/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 129.4/199.4 MB 43.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 132.0/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 134.8/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 137.0/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 139.6/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 141.5/199.4 MB 46.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 143.4/199.4 MB 46.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 145.2/199.4 MB 43.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 147.4/199.4 MB 43.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 148.8/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 151.2/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 153.0/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 155.1/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 157.2/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 158.4/199.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 159.4/199.4 MB 36.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 161.4/199.4 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 163.1/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 165.0/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 166.9/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 168.6/199.4 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 170.8/199.4 MB 38.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 172.5/199.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 174.6/199.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 175.8/199.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 177.7/199.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 179.7/199.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 181.7/199.4 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.3/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.7/199.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 186.7/199.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 188.4/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 190.8/199.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 192.2/199.4 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  194.3/199.4 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.5/199.4 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.2/199.4 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 199.4/199.4 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/9.9 MB 50.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.4/9.9 MB 31.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.4/9.9 MB 35.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.9 MB 37.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.5/9.9 MB 37.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/9.9 MB 38.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/9.9 MB 33.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 30.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.3/286.3 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.2/2.4 MB 46.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 37.6 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.25.2 safetensors-0.4.5 sentence-transformers-3.2.0 tokenizers-0.20.1 torch-2.4.1 transformers-4.45.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting termcolor\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: termcolor\n",
      "Successfully installed termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Installing collected packages: absl-py\n",
      "Successfully installed absl-py-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install absl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reactivex\n",
      "  Using cached reactivex-4.0.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from reactivex) (4.11.0)\n",
      "Using cached reactivex-4.0.4-py3-none-any.whl (217 kB)\n",
      "Installing collected packages: reactivex\n",
      "Successfully installed reactivex-4.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install reactivex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.6.1-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\algar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\algar\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\algar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 383.7/383.7 kB 11.7 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.0/78.0 kB ? eta 0:00:00\n",
      "Downloading jiter-0.6.1-cp312-none-win_amd64.whl (198 kB)\n",
      "   ---------------------------------------- 0.0/199.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 199.0/199.0 kB ? eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: jiter, h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-qLG5ExLqpWa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import sentence_transformers\n",
    "\n",
    "from typing import Callable\n",
    "from IPython import display\n",
    "\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.agents import basic_agent\n",
    "from concordia.utils import html as html_lib\n",
    "from concordia.environment import game_master\n",
    "from concordia.language_model import gpt_model\n",
    "from concordia.document import interactive_document\n",
    "from concordia import components as generic_components\n",
    "from concordia.associative_memory import blank_memories\n",
    "from concordia.components import agent as agent_components\n",
    "from concordia.factory.environment import basic_game_master\n",
    "from concordia.associative_memory import associative_memory\n",
    "from concordia.associative_memory import formative_memories\n",
    "from concordia.associative_memory import importance_function\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.thought_chains import thought_chains as thought_chains_lib\n",
    "from concordia.environment.scenes import conversation as conversation_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vijuHCp7Ypxd"
   },
   "source": [
    "### Language Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mFRr48R7b3QB"
   },
   "outputs": [],
   "source": [
    "GPT_API_KEY = 'lm-studio' #@param {type: 'string'}\n",
    "GPT_MODEL_NAME = 'LM Studio Community/Meta-Llama-3-8B-Instruct-GGUF' #@param {type: 'string'}\n",
    "\n",
    "if not GPT_API_KEY:\n",
    "  raise ValueError('GPT_API_KEY is required.')\n",
    "\n",
    "model = gpt_model.GptLanguageModel(api_key=GPT_API_KEY,\n",
    "                                   model_name=GPT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55QorImHYpxe"
   },
   "source": [
    "### Sentence Encoder Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I3OtW8flCJSC"
   },
   "outputs": [],
   "source": [
    "st_model = sentence_transformers.SentenceTransformer(\n",
    "    'sentence-transformers/all-mpnet-base-v2')\n",
    "embedder = lambda x: st_model.encode(x, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9HYjZgyakc_"
   },
   "source": [
    "## Configuring the generic knowledge of players and GM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKBLCvT2anME"
   },
   "source": [
    "### Define the premise, subgoal (agents' goal), goal, and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1Da51MphYY23"
   },
   "outputs": [],
   "source": [
    "PROJECT_PREMISE = (\n",
    "    ' The study of disinformation and its rapid spread poses new challenges'\n",
    "    ' beyond the established conventions of traditional media studies. Unlike'\n",
    "    ' misinformation, disinformation involves the intentional spread of false'\n",
    "    ' or misleading information to manipulate. Understanding how fake news'\n",
    "    ' spreads and evaluating the effectiveness of various strategies to prevent'\n",
    "    ' its spread is crucial in todayÂ´s information landscape.'\n",
    ")\n",
    "\n",
    "PROJECT_SUBGOAL = (\n",
    "    ' Discuss the veracity of the information you receive. Evaluate and share your thoughts on '\n",
    "    ' whether the news might be true or false, and explain your reasoning. Consider the source, '\n",
    "    ' your own knowledge, and any available verification tools. '\n",
    ")\n",
    "\n",
    "PROJECT_GOAL = (\n",
    "    ' An agent introduces a piece of fake news and you need to observe its spread. '\n",
    "    ' Observe the effect it has on each character and assess the effectiveness '\n",
    "    ' of different strategies and tools used to prevent the spread of fake news,'\n",
    "    ' providing insights into which methods are most successful.'\n",
    ")\n",
    "\n",
    "PROJECT_CONTEXT = (\n",
    "    ' A group of friends is having a casual conversation when one of them suddenly '\n",
    "    ' shares a surprising piece of news. The friends then discuss whether the news '\n",
    "    ' is true or false, evaluating the information based on their knowledge, the '\n",
    "    ' credibility of the source, and any verification tools they have. This setting '\n",
    "    ' provides a realistic scenario for observing the spread of fake news and testing '\n",
    "    ' strategies to prevent it.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rOaCcfgvk-yE"
   },
   "outputs": [],
   "source": [
    "agent_goal = PROJECT_SUBGOAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNFf0JakawLE"
   },
   "source": [
    "### Generic memories are memories that all players and GM share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "b8vWoQ6by51N"
   },
   "outputs": [],
   "source": [
    "simulation_premise_component = generic_components.constant.ConstantComponent(\n",
    "    state=PROJECT_CONTEXT,\n",
    "    name='The context of the current situation',\n",
    ")\n",
    "\n",
    "importance_model = importance_function.ConstantImportanceModel()\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LztBoxhZa4_f"
   },
   "source": [
    "### Make the clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TeVYseoD2WYa"
   },
   "outputs": [],
   "source": [
    "UPDATE_INTERVAL = datetime.timedelta(seconds=10)\n",
    "\n",
    "SETUP_TIME = datetime.datetime(hour=8, year=2024, month=6, day=1)\n",
    "\n",
    "START_TIME = datetime.datetime(hour=14, year=2024, month=7, day=1)\n",
    "clock = game_clock.MultiIntervalClock(\n",
    "    start=SETUP_TIME,\n",
    "    step_sizes=[UPDATE_INTERVAL, datetime.timedelta(seconds=10)])\n",
    "\n",
    "NUM_ROUNDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBCXUQ8sayzj"
   },
   "source": [
    "## Functions to build the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JysvgpA-8n1q"
   },
   "outputs": [],
   "source": [
    "blank_memory_factory = blank_memories.MemoryFactory(\n",
    "    model=model,\n",
    "    embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock_now=clock.now,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8UhdvLiVw7gf"
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from typing import Any\n",
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass(frozen=True, kw_only=True)\n",
    "class AgentConfig:\n",
    "  \"\"\"A card that describes a player.\n",
    "\n",
    "  Attributes:\n",
    "    name: name of the agent.\n",
    "    gender: the gender of the agent.\n",
    "    traits: any traits to use while generating formative memories.\n",
    "    political_ideology: the set of beliefs about political values and the role of government that influence the agent's behavior and decisions.\n",
    "    biography: a description of the agent.\n",
    "    context: agent formative memories will be generated with this context\n",
    "    specific_memories: inject these specific memories. Split memories at newline\n",
    "      characters. Can be left blank if not used.\n",
    "    goal: defines agents goal. Can be left blank if not used.\n",
    "  \"\"\"\n",
    "\n",
    "  name: str\n",
    "  gender: str\n",
    "  traits: str\n",
    "  political_ideology: str\n",
    "  biography: str = ''\n",
    "  goal: str = ''\n",
    "  selected_works : Sequence[str]\n",
    "\n",
    "def specific_memories_from_selected_works(player_config: AgentConfig) -> str:\n",
    "  \"\"\"Create memories per player using their role as moderator or debater.\"\"\"\n",
    "  specific_memories = []\n",
    "  player_name = player_config.name\n",
    "  for work in player_config.selected_works:\n",
    "    specific_memories += [(\n",
    "        f'[writing] of {player_name}: \"{work}\"')]\n",
    "    idea = model.sample_text(\n",
    "        (f'Consider the paper summarised here: \"{work}\". Without repeating '\n",
    "         'the title, a two sentence TLDR of its most important and distinctive '\n",
    "         'idea is that '),\n",
    "        terminators=('\\n',))\n",
    "    specific_memories += [(\n",
    "        f'[idea] of {player_name}: {idea}')]\n",
    "    print(f'idea: {idea}.')\n",
    "\n",
    "  return specific_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2gSHOPX9HTFS"
   },
   "outputs": [],
   "source": [
    "def cat_with_dropout(inputs : list[str], dropout_rate: float = 0.2) -> str:\n",
    "  result = '\\n'.join([x for x in inputs if random.random() > dropout_rate])\n",
    "  return result\n",
    "\n",
    "class MindStream(agent_components.observation.Observation):\n",
    "  \"\"\"The MindStream class defines an observation component for an agent, retrieving and logging memories within a specific timeframe\"\"\"\n",
    "  def state(self):\n",
    "    mems = self._memory.retrieve_time_interval(\n",
    "        self._clock_now() - self._timeframe, self._clock_now(), add_time=True\n",
    "    )\n",
    "\n",
    "    if self._verbose:\n",
    "      self._log('\\n'.join(mems) + '\\n')\n",
    "    return '\\n'.join(mems) + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "As465DbcsAwZ"
   },
   "outputs": [],
   "source": [
    "def build_agent(\n",
    "    agent_config,\n",
    "    unused_player_names: list[str],\n",
    "    unused_measurements: measurements_lib.Measurements | None = None,\n",
    "):\n",
    "  \"\"\"This function builds an agent using the provided configuration. It initializes the agent's memory,\n",
    "    biography, traits, observations, and other components, and then creates an instance of BasicAgent.\"\"\"\n",
    "\n",
    "  agent_name = agent_config.name\n",
    "  mem = blank_memory_factory.make_blank_memory()\n",
    "\n",
    "  memories_from_work = specific_memories_from_selected_works(agent_config)\n",
    "\n",
    "  for item in memories_from_work:\n",
    "    if item:\n",
    "      mem.add(item, importance=1.0)\n",
    "\n",
    "  bio = generic_components.constant.ConstantComponent(\n",
    "      state=agent_config.biography, name='biography'\n",
    "  )\n",
    "  time = generic_components.report_function.ReportFunction(\n",
    "      name='Current time',\n",
    "      function=clock.current_time_interval_str,\n",
    "  )\n",
    "  traits = generic_components.constant.ConstantComponent(\n",
    "      state=agent_config.traits, name='psychological traits'\n",
    "  )\n",
    "  political_ideology = generic_components.constant.ConstantComponent(\n",
    "      state=agent_config.political_ideology, name='political ideology'\n",
    "  )\n",
    "  current_obs = MindStream(\n",
    "      agent_name=agent_name,\n",
    "      clock_now=clock.now,\n",
    "      memory=mem,\n",
    "      timeframe=clock.get_step_size()*2,\n",
    "      component_name='current observations',\n",
    "  )\n",
    "\n",
    "  convo_so_far = generic_components.report_function.ReportFunction(\n",
    "    name='memory of the conversation',\n",
    "    function=lambda: cat_with_dropout(mem.retrieve_by_regex(r' -- \"')),\n",
    "    )\n",
    "  \n",
    "  ideas = generic_components.report_function.ReportFunction(\n",
    "        name='ideas',\n",
    "        function=lambda: cat_with_dropout(mem.retrieve_by_regex(r'\\[idea\\]')),\n",
    "        )\n",
    "  \n",
    "  writing = generic_components.report_function.ReportFunction(\n",
    "        name='writings',\n",
    "        function=lambda: cat_with_dropout(mem.retrieve_by_regex(r'\\[writing\\]')),\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "  # Setup the reflection component and its related components.\n",
    "  topic_of_debate = generic_components.report_function.ReportFunction(\n",
    "      name='Topic of the workshop', function=lambda: PROJECT_PREMISE\n",
    "  )\n",
    "  goal_of_debate = generic_components.report_function.ReportFunction(\n",
    "      name='Goal of the workshop', function=agent_goal\n",
    "  )\n",
    "  # The agent's subpersonal intuition contains a bias toward thinking that\n",
    "  # they themselves are the best.\n",
    "\n",
    "  reflection = agent_components.creative_reflection.CreativeReflection(\n",
    "      name='reflection',\n",
    "      model=model,\n",
    "      memory=mem,\n",
    "      agent_name=agent_name,\n",
    "      source_of_abstraction=[convo_so_far, writing, ideas],\n",
    "      topic_component = topic_of_debate,\n",
    "      clock_now=clock.now,\n",
    "      verbose=False,\n",
    "  )\n",
    "  all_components = [\n",
    "          bio,\n",
    "          traits,\n",
    "          political_ideology,\n",
    "          topic_of_debate,\n",
    "          goal_of_debate,\n",
    "          reflection,\n",
    "          current_obs]\n",
    "  agent = basic_agent.BasicAgent(\n",
    "      model,\n",
    "      agent_name=agent_name,\n",
    "      clock=clock,\n",
    "      components=[time] +  all_components,\n",
    "      update_interval=UPDATE_INTERVAL,\n",
    "  )\n",
    "\n",
    "  return agent, mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qt8CK2mMbD7q"
   },
   "source": [
    "## Configure and build the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5RU3ZV4oIknW"
   },
   "outputs": [],
   "source": [
    "# Define a function to generate random traits for an agent\n",
    "TRAIT_LEVELS = [\"low\", \"medium\", \"high\"] # range of possible levels for traits\n",
    "\n",
    "def make_random_traits() -> str:\n",
    "  return str({\n",
    "      \"extraversion\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"neuroticism\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"openness\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"conscientiousness\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"agreeableness\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"susceptibility\": np.random.choice(TRAIT_LEVELS),\n",
    "      \"critical thinking\": np.random.choice(TRAIT_LEVELS),\n",
    "  })\n",
    "\n",
    "\n",
    "# Create player configurations, each represented by an AgentConfig object\n",
    "player_configs = [\n",
    "    AgentConfig(\n",
    "        name=\"Alice Johnson\",\n",
    "        gender=\"female\",\n",
    "        traits=make_random_traits(),\n",
    "        political_ideology=\"liberal\",\n",
    "        biography=(\n",
    "            \"Alice Johnson, a political activist and community organizer, is known for her \"\n",
    "            \"advocacy on social justice and environmental issues. With a background in sociology, \"\n",
    "            \"Alice has spent years working with grassroots organizations to promote equality and \"\n",
    "            \"sustainable development. Her liberal views are deeply rooted in a belief in the power \"\n",
    "            \"of community action and progressive policies to drive change.\"\n",
    "        ),\n",
    "        selected_works=[\n",
    "            (\n",
    "                \"The Power of Community: A guide to grassroots organizing and the impact of collective action \"\n",
    "                \"on local and national politics. This work emphasizes the importance of community engagement and \"\n",
    "                \"advocacy in promoting social justice and environmental sustainability.\"\n",
    "            ),\n",
    "            (\n",
    "                \"Breaking the Chains: Exploring the intersection of social justice and environmental advocacy, \"\n",
    "                \"this book discusses the role of policy in addressing systemic inequalities and environmental degradation.\"\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    AgentConfig(\n",
    "        name=\"David Smith\",\n",
    "        gender=\"male\",\n",
    "        traits=make_random_traits(),\n",
    "        political_ideology=\"conservative\",\n",
    "        biography=(\n",
    "            \"David Smith is a business executive and political commentator known for his conservative views. \"\n",
    "            \"With a career spanning over two decades in the corporate world, David emphasizes the importance \"\n",
    "            \"of free markets, personal responsibility, and limited government. His commentaries often critique \"\n",
    "            \"progressive policies, advocating instead for traditional values and economic conservatism.\"\n",
    "        ),\n",
    "        selected_works=[\n",
    "            (\n",
    "                \"The Free Market Solution: A comprehensive analysis of how free market principles can address \"\n",
    "                \"economic and social issues more effectively than government intervention. David argues for \"\n",
    "                \"reducing regulations and promoting entrepreneurship.\"\n",
    "            ),\n",
    "            (\n",
    "                \"Preserving Our Values: In this book, David explores the importance of maintaining traditional values \"\n",
    "                \"and cultural heritage in the face of modern challenges. He discusses the role of family, faith, and community \"\n",
    "                \"in fostering a stable and prosperous society.\"\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    AgentConfig(\n",
    "        name=\"Emma Thompson\",\n",
    "        gender=\"female\",\n",
    "        traits=make_random_traits(),\n",
    "        political_ideology=\"moderate\",\n",
    "        biography=(\n",
    "            \"Emma Thompson, a journalist and independent political analyst, is known for her balanced and pragmatic approach \"\n",
    "            \"to political issues. Emma's work focuses on bridging the gap between polarized political ideologies, advocating for \"\n",
    "            \"policies that are practical and beneficial for the majority. Her moderate stance often emphasizes the need for \"\n",
    "            \"compromise and bipartisanship in policymaking.\"\n",
    "        ),\n",
    "        selected_works=[\n",
    "            (\n",
    "                \"Finding Common Ground: This book explores the art of compromise in politics, highlighting successful case studies \"\n",
    "                \"where bipartisan efforts have led to meaningful change. Emma discusses the importance of dialogue and understanding \"\n",
    "                \"in resolving political conflicts.\"\n",
    "            ),\n",
    "            (\n",
    "                \"The Pragmatic Approach: Emma provides an in-depth analysis of various political issues from a moderate perspective, \"\n",
    "                \"emphasizing solutions that are effective and realistic, rather than ideologically driven.\"\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    AgentConfig(\n",
    "        name=\"Michael Chen\",\n",
    "        gender=\"male\",\n",
    "        traits=make_random_traits(),\n",
    "        political_ideology=\"libertarian\",\n",
    "        biography=(\n",
    "            \"Michael Chen is a technology entrepreneur and libertarian advocate who champions individual freedom and minimal government \"\n",
    "            \"intervention. With a background in software development and startups, Michael believes in the power of innovation and personal \"\n",
    "            \"initiative to drive societal progress. His libertarian views are reflected in his emphasis on privacy, free speech, and market \"\n",
    "            \"deregulation.\"\n",
    "        ),\n",
    "        selected_works=[\n",
    "            (\n",
    "                \"The Future of Innovation: Michael discusses how minimal government intervention and maximum personal freedom can spur technological \"\n",
    "                \"advancements and economic growth. He explores case studies of successful startups that thrived in deregulated environments.\"\n",
    "            ),\n",
    "            (\n",
    "                \"Freedom and Privacy: This work delves into the importance of protecting individual rights in the digital age. Michael examines the threats \"\n",
    "                \"to privacy and free speech posed by government surveillance and corporate control, advocating for robust protections and personal autonomy.\"\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PyFySEpmCHIC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idea: the key to successful politics lies not in confrontation or polarization, but rather in fostering open dialogue and finding common ground between opposing parties through compromise. By doing so, meaningful change can be achieved, as demonstrated by real-world case studies showcasing the positive outcomes of bipartisan efforts..\n",
      "idea: Minimal government intervention and maximum personal freedom are essential for fostering innovation and driving economic growth by allowing entrepreneurs to take risks and pursue new ideas without regulatory burdens. The paper highlights successful startups that flourished in deregulated environments as examples of how this approach can lead to significant technological advancements and prosperity..\n",
      "idea: grassroots organizing and collective action have the power to drive significant change at both local and national levels by leveraging the strengths of community engagement and advocacy. By building strong, inclusive communities and amplifying marginalized voices, individuals can collectively push for social justice and environmental sustainability, leading to tangible impacts on politics and policy-making..\n",
      "idea: According to the paper, the author advocates for reducing regulatory barriers to unleash entrepreneurial spirit and promote economic growth, arguing that free market principles can more effectively address social and economic issues than government intervention. By doing so, the author suggests that individuals and businesses are better equipped to drive innovation and prosperity, rather than relying on government controls..\n",
      "idea: Emma's approach focuses on finding practical and achievable solutions to complex political problems by setting aside ideological biases and instead prioritizing effectiveness. By doing so, she aims to facilitate constructive dialogue and collaboration among individuals with differing perspectives, ultimately leading to more sustainable and equitable outcomes..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algar\\Documents\\Travail\\GitHub\\ConcordiaSims\\concordia\\associative_memory\\associative_memory.py:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idea: the author argues that government surveillance and corporate control pose significant threats to individual privacy and freedom, and that strong legal protections are necessary to safeguard these fundamental rights in the digital age. By advocating for robust protections and personal autonomy, the author seeks to empower individuals to exercise their rights and maintain control over their own data and online activities..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algar\\Documents\\Travail\\GitHub\\ConcordiaSims\\concordia\\associative_memory\\associative_memory.py:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idea: The book argues that environmental degradation and social injustice are interconnected issues that require a holistic approach to address, highlighting the need for policymakers to prioritize policies that simultaneously promote social justice and environmental sustainability. By recognizing the systemic inequalities perpetuated by environmental degradation, the book advocates for a more equitable distribution of resources and benefits, ultimately seeking to \"break the chains\" of oppression and create a more just and sustainable future..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algar\\Documents\\Travail\\GitHub\\ConcordiaSims\\concordia\\associative_memory\\associative_memory.py:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idea: the preservation of traditional values and cultural heritage is crucial for building a stable and prosperous society, and this can be achieved through the support of family, faith, and community. By maintaining these core elements, individuals can navigate modern challenges while staying true to their roots and preserving their sense of identity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algar\\Documents\\Travail\\GitHub\\ConcordiaSims\\concordia\\associative_memory\\associative_memory.py:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Observation.__init__() got an unexpected keyword argument 'agent_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m memories \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mNUM_PLAYERS) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m----> 8\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mplayer_configs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mNUM_PLAYERS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# All players get the same `player_names`.\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer_names\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_PLAYERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# All players get the same `measurements` object.\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_PLAYERS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemories\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[29], line 31\u001b[0m, in \u001b[0;36mbuild_agent\u001b[1;34m(agent_config, unused_player_names, unused_measurements)\u001b[0m\n\u001b[0;32m     25\u001b[0m traits \u001b[38;5;241m=\u001b[39m generic_components\u001b[38;5;241m.\u001b[39mconstant\u001b[38;5;241m.\u001b[39mConstantComponent(\n\u001b[0;32m     26\u001b[0m     state\u001b[38;5;241m=\u001b[39magent_config\u001b[38;5;241m.\u001b[39mtraits, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsychological traits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m political_ideology \u001b[38;5;241m=\u001b[39m generic_components\u001b[38;5;241m.\u001b[39mconstant\u001b[38;5;241m.\u001b[39mConstantComponent(\n\u001b[0;32m     29\u001b[0m     state\u001b[38;5;241m=\u001b[39magent_config\u001b[38;5;241m.\u001b[39mpolitical_ideology, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolitical ideology\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m current_obs \u001b[38;5;241m=\u001b[39m \u001b[43mMindStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclock_now\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_step_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent observations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m convo_so_far \u001b[38;5;241m=\u001b[39m generic_components\u001b[38;5;241m.\u001b[39mreport_function\u001b[38;5;241m.\u001b[39mReportFunction(\n\u001b[0;32m     40\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory of the conversation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     41\u001b[0m   function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: cat_with_dropout(mem\u001b[38;5;241m.\u001b[39mretrieve_by_regex(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     42\u001b[0m   )\n\u001b[0;32m     44\u001b[0m ideas \u001b[38;5;241m=\u001b[39m generic_components\u001b[38;5;241m.\u001b[39mreport_function\u001b[38;5;241m.\u001b[39mReportFunction(\n\u001b[0;32m     45\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mideas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     46\u001b[0m       function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: cat_with_dropout(mem\u001b[38;5;241m.\u001b[39mretrieve_by_regex(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[idea\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     47\u001b[0m       )\n",
      "\u001b[1;31mTypeError\u001b[0m: Observation.__init__() got an unexpected keyword argument 'agent_name'"
     ]
    }
   ],
   "source": [
    "NUM_PLAYERS = len(player_configs)\n",
    "player_names = [player.name for player in player_configs][:NUM_PLAYERS]\n",
    "measurements = measurements_lib.Measurements()\n",
    "\n",
    "players = []\n",
    "memories = {}\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_PLAYERS) as pool:\n",
    "  for agent, mem in pool.map(build_agent,\n",
    "                             player_configs[:NUM_PLAYERS],\n",
    "                             # All players get the same `player_names`.\n",
    "                             [player_names] * NUM_PLAYERS,\n",
    "                             # All players get the same `measurements` object.\n",
    "                             [measurements] * NUM_PLAYERS):\n",
    "    players.append(agent)\n",
    "    memories[agent.name] = mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBp_-8OP1Crr"
   },
   "source": [
    "### Summarise the perspective of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxB2M54iiz0M"
   },
   "outputs": [],
   "source": [
    "player_logs = []\n",
    "player_log_names = []\n",
    "for player in players:\n",
    "  name = player.name\n",
    "  detailed_story = '\\n'.join(memories[player.name].retrieve_recent(\n",
    "      k=1000, add_time=True))\n",
    "  summary = player.state().splitlines()\n",
    "\n",
    "  all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "  all_player_mem = ['Player state:', summary, 'Memories:'] + all_player_mem\n",
    "  player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "  player_logs.append(player_html)\n",
    "  player_log_names.append(f'{name}')\n",
    "\n",
    "tabbed_html = html_lib.combine_html_pages(\n",
    "    player_logs,\n",
    "    player_log_names,\n",
    "    summary='',\n",
    "    title='Backstory of the players',\n",
    ")\n",
    "\n",
    "tabbed_html = html_lib.finalise_html(tabbed_html)\n",
    "display.HTML(tabbed_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vt8ggYUrW8M"
   },
   "source": [
    "## Build GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06p6Sk1GVq46"
   },
   "outputs": [],
   "source": [
    "call_to_speech = (\n",
    "    'Given the above, generate what {name} would say next? Take their '\n",
    "    'ideas and reflections and the goal of the workship into account. Respond '\n",
    "    'in the format `{name} -- \"...\"`'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gP6lcN_AIPPR"
   },
   "outputs": [],
   "source": [
    "clock.advance()\n",
    "\n",
    "debate_event = (\n",
    "    f'{players[0].name}, {players[1].name}, {players[2].name}, and {players[3].name} are in a'\n",
    "    f' workshop.\\n Their current goal is {agent_goal}.'\n",
    ")\n",
    "\n",
    "for player in players:\n",
    "  player.observe(debate_event)\n",
    "\n",
    "for player in players:\n",
    "  player.observe('It is time to for a discussion now')\n",
    "\n",
    "\n",
    "convo_scene = conversation_scene.make_conversation_game_master(\n",
    "    players,\n",
    "    clock=clock,\n",
    "    model=model,\n",
    "    memory_factory=blank_memory_factory,\n",
    "    name='Disinformation',\n",
    "    premise=debate_event,\n",
    "    call_to_speech=call_to_speech,\n",
    "    review_participants=True,\n",
    "    check_for_termination=False,\n",
    "    randomise_initiative=True,\n",
    ")\n",
    "with clock.higher_gear():\n",
    "  clock.advance()\n",
    "  output = convo_scene.run_episode(10)\n",
    "\n",
    "first_convo_html = html_lib.PythonObjectToHTMLConverter(\n",
    "    convo_scene.get_history()\n",
    ").convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql3eNvwiS8C3"
   },
   "outputs": [],
   "source": [
    "display.HTML(first_convo_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qso4kVDwRoct"
   },
   "outputs": [],
   "source": [
    "essays = []\n",
    "for player in players:\n",
    "  prompt = interactive_document.InteractiveDocument(model)\n",
    "  prompt.statement(player.state())\n",
    "  agent_name = player.name\n",
    "  result = prompt.open_question(\n",
    "      'Generate an essay on the topic of the workshop from the perspective of'\n",
    "      f' {agent_name}. The goal of the essay is to summarise the conversation'\n",
    "      f' and {agent_goal}. Write in the style of {agent_name}, taking their'\n",
    "      ' ideas and reflections into account. Format the output as html',\n",
    "\n",
    "      max_tokens=5000,\n",
    "      terminators=(),\n",
    "  )\n",
    "  essays.append(result)\n",
    "\n",
    "tabbed_html = html_lib.combine_html_pages(\n",
    "    essays,\n",
    "    [player.name for player in players],\n",
    "    summary='',\n",
    "    title='First essays by participants',\n",
    ")\n",
    "\n",
    "first_essays_html = html_lib.finalise_html(tabbed_html)\n",
    "display.HTML(first_essays_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFgG5xlyYpxh"
   },
   "source": [
    "### Game Master Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkwpeB4_1IFl"
   },
   "outputs": [],
   "source": [
    "game_master_memory = associative_memory.AssociativeMemory(\n",
    "    sentence_embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock=clock.now)\n",
    "primary_environment, game_master_memory = (\n",
    "    basic_game_master.build_game_master(\n",
    "        model=model,\n",
    "        embedder=embedder,\n",
    "        importance_model=importance_model_gm,\n",
    "        clock=clock,\n",
    "        players=players,\n",
    "        shared_memories=[f'{PROJECT_PREMISE}\\n{PROJECT_CONTEXT}'],\n",
    "        shared_context=f'{PROJECT_GOAL}',\n",
    "        blank_memory_factory=blank_memory_factory,\n",
    "        memory=game_master_memory,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMHojBanb3QF"
   },
   "outputs": [],
   "source": [
    "episode_length = 4  # @param {type: 'integer'}\n",
    "for _ in range(episode_length):\n",
    "  primary_environment.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJnxoWEEb3QF"
   },
   "outputs": [],
   "source": [
    "results_html = basic_game_master.create_html_log(\n",
    "    model=model,\n",
    "    primary_environment=primary_environment,\n",
    "    secondary_environments=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDFeLjhOb3QF"
   },
   "outputs": [],
   "source": [
    "display.HTML(results_html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
